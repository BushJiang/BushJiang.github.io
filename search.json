[{"title":"写给新读者的导航","url":"/2025/01/07/写给新读者的导航/","content":"\n你好啊朋友，我是江浩，一名AI大陆的探险者，目前主要关注向量数据库和大语言模型领域。\n\n在博客里，我会探秘AI神奇能力的背后原理。别担心，我会用有趣的言语和生动的类比来解释这些原理。你是否好奇，孙悟空 + 红楼梦 - 西游记 = ？那就来了解下向量嵌入吧。当你接触到向量嵌入后，你可能会问，既然已经有了稠密向量，为什么还需要稀疏向量？嗯，如果说稠密向量是领域专家，那么稀疏向量就是一个聪明的门外汉，面对领域外的知识，请教后者反而更合适。\n\n除了原理探秘，我还会用AI开发一些有趣的应用，比如，用白话文搜索语义相似的古诗词，让你体验一把“文艺青年”的乐趣。或者，开发一个“鲁迅说没有”的RAG应用，验证把所谓的“鲁迅名言”是否属实，它的原文又是怎样的。甚至，我还想和牛魔王对话，问问他更爱铁扇公主还是玉面狐狸。哈哈，有趣的想法太多，慢慢实现。\n\n对了，我在探索AI大陆时，也采集了不少鲜美的果实————优质资源，我会整理好了分享给你。\n\nAI大陆有趣又神奇，朋友，我邀请你和我同行。\n\nChangeLog\n2025-01-07","categories":["杂谈"]},{"title":"如何假装文艺青年，怎么把大白话“变成”古诗词？","url":"/2024/09/16/如何假装文艺青年，怎么把大白话“变成”古诗词？/","content":"\n午后细雨绵绵，你独倚窗边，思绪万千，于是拿出手机，想发一条朋友圈抒发情怀，随便展示一下文采。奈何好不容易按出几个字，又全部删除。“今天的雨好大”展示不出你的文采。你灵机一动，如果有一个搜索引擎，能搜索出和“今天的雨好大”意思相近的古诗词，岂不妙哉！\n\n使用向量数据库就可以实现，代码还不到100行，一起来试试吧。我们会从零开始安装向量数据库 Milvus，向量化古诗词数据集，然后创建集合，导入数据，创建索引，最后实现语义搜索功能。\n\n本文首发于 Zilliz 公众号。文中代码的 Notebook 在[这里](https://pan.baidu.com/s/1Su0U65G6ZXXuzUy8VO3_cA?pwd=esca)下载。\n\n## 0 准备工作\n首先安装向量数据库 Milvus。因为 Milvus 是运行在 docker 中的，所以需要先安装 Docker Desktop。MacOS 系统安装方法：[Install Docker Desktop on Mac](https://docs.docker.com/desktop/install/mac-install/) ，Windows 系统安装方法：[Install Docker Desktop on Windows](https://docs.docker.com/desktop/install/windows-install/)\n\n然后安装 Milvus。Milvus 版本：>=2.5.0\n下载安装脚本：\n```shell\ncurl -sfL https://raw.githubusercontent.com/milvus-io/milvus/master/scripts/standalone_embed.sh -o standalone_embed.sh\n```\n\n运行 Milvus：\n```shell\nbash standalone_embed.sh start\n```\n\n安装依赖。pymilvus >= 2.5.0\n```shell\npip install pymilvus \"pymilvus[model]\" torch \n```\n\n下载古诗词数据集[^1] TangShi.json。它的格式是这样的：\n\n```json\n[\n\t{\n\t\t\"author\": \"太宗皇帝\",\n\t\t\"paragraphs\": [\n\t\t\t\"秦川雄帝宅，函谷壮皇居。\"\n\t\t],\n\t\t\"title\": \"帝京篇十首 一\",\n\t\t\"id\": 20000001,\n\t\t\"type\": \"唐诗\"\n\t},\n\t...\n]\n```\n\n准备就绪，正式开始啦。\n## 1 向量化文本\n为了实现语义搜索，我们需要先把文本向量化。你可以理解为把不同类型的信息（如文字、图像、声音）翻译成计算机可以理解的数字语言。计算机理解了，才能帮你找到语义相近的诗句。\n\n先定义两个函数，一个用来初始化嵌入模型（也就是用来向量化的模型）的实例，另一个是调用嵌入模型的实例，把输入的文档向量化。\n\n初始化嵌入模型的实例：\n```python\nfrom tqdm import tqdm\nimport torch\nfrom pymilvus.model.hybrid import BGEM3EmbeddingFunction\nfrom typing import List, Dict, Union\nfrom scipy.sparse import csr_array\n\n# 初始化嵌入模型的实例\ndef init_embedding_model() -> BGEM3EmbeddingFunction:\n    # 检查是否有可用的CUDA设备\n    device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n    # 根据设备选择是否使用fp16\n    use_fp16 = device.startswith(\"cuda\")\n    # 创建嵌入模型实例\n    bge_m3_ef = BGEM3EmbeddingFunction(\n        model_name=\"BAAI/bge-m3\",\n        device=device,\n        use_fp16=use_fp16\n    )\n    return bge_m3_ef\n\nbge_m3_ef = init_embedding_model()\n```\n\n向量化文档：\n```python\n# 把文档向量化\ndef vectorize_docs(docs: List[str]) -> Dict[str, Union[List[List[float]], List[csr_array]]]:\n    # 验证 docs 是否为字符串列表\n    if not isinstance(docs, list) or not all(isinstance(doc, str) for doc in docs):\n        raise ValueError(\"docs必须是字符串列表。\")\n    if bge_m3_ef is None:\n        raise ValueError(\"嵌入模型未初始化，请先调用 initialize_embedding_model 函数。\")\n    # 把输入的文本向量化\n    return bge_m3_ef.encode_documents(docs)\n```\n\n准备好后，我们就可以向量化整个数据集了。首先读取数据集 TangShi.json 中的数据，把其中的 paragraphs 字段向量化，然后写入 TangShi_vector.json 文件。如果你是第一次使用 Milvus，运行下面的代码时还会安装必要的依赖。\n\n```python\n# 读取 json 文件，把paragraphs字段向量化\nwith open(\"TangShi.json\", 'r', encoding='utf-8') as file:\n\tdata_list = json.load(file)\n\tdocs = [data['paragraphs'][0] for data in data_list]\n\n# 向量化文本数据\nvectors = vectorize_docs(docs)\n\n# 将向量添加到原始文本中\nfor data, vector in zip(data_list, vectors['dense']):\n    # 将 NumPy 数组转换为 Python 的普通列表\n\tdata['vector'] = vector.tolist()\n\n# 将更新后的文本内容写入新的json文件\nwith open(\"TangShi_vector.json\", 'w', encoding='utf-8') as outfile:\n\tjson.dump(data_list, outfile, ensure_ascii=False, indent=4)\n```\n\n如果一切顺利，你会得到 TangShi_vector.json 文件，它增加了 vector 字段，它的值是一个字符串列表，也就是“向量”。\n\n```json\n[\n\t{\n\t\t\"author\": \"太宗皇帝\",\n\t\t\"paragraphs\": [\n\t\t\t\"秦川雄帝宅，函谷壮皇居。\"\n\t\t],\n\t\t\"title\": \"帝京篇十首 一\",\n\t\t\"id\": 20000001,\n\t\t\"type\": \"唐诗\",\n\t\t\"vector\": [\n\t\t\t0.005114779807627201,\n\t\t\t0.033538609743118286,\n\t\t\t0.020395483821630478,\n\t\t\t...\n\t\t]\n\t},\n\t{\n\t\t\"author\": \"太宗皇帝\",\n\t\t\"paragraphs\": [\n\t\t\t\"绮殿千寻起，离宫百雉余。\"\n\t\t],\n\t\t\"title\": \"帝京篇十首 一\",\n\t\t\"id\": 20000002,\n\t\t\"type\": \"唐诗\",\n\t\t\"vector\": [\n\t\t\t-0.06334448605775833,\n\t\t\t0.0017451602034270763,\n\t\t\t-0.0010646708542481065,\n\t\t\t...\n\t\t]\n\t},\n\t...\n]\n```\n\n## 2 创建集合\n接下来我们要把向量数据导入向量数据库。当然，我们得先在向量数据库中创建一个集合，用来容纳向量数据。\n```python\nfrom pymilvus import MilvusClient\n# 连接向量数据库，创建client实例\nclient = MilvusClient(uri=\"http://localhost:19530\")\n\n# 指定集合名称\ncollection_name = \"TangShi\"\n```\n\n为了避免向量数据库中存在同名集合，产生干扰，创建集合前先删除同名集合。\n```python\n# 检查同名集合是否存在，如果存在则删除\nif client.has_collection(collection_name):\n\tprint(f\"Collection {collection_name} already exists\")\n\ttry:\n\t\t# 删除同名集合\n\t\tclient.drop_collection(collection_name)\n\t\tprint(f\"Deleted the collection {collection_name}\")\n\texcept Exception as e:\n\t\tprint(f\"Error occurred while dropping collection: {e}\")\n```\n\n我们把数据填入 excel 表格前，需要先设计好表头，规定有哪些字段，各个字段的数据类型是怎样的。向量数据库也是一样，它的“表头”就是 schema，模式。\n```python\nfrom pymilvus import DataType\n\n# 创建集合模式\nschema = MilvusClient.create_schema(\n\tauto_id=False,\n\tenable_dynamic_field=True,\n\tdescription=\"TangShi\"\n)\n\n# 添加字段到schema\nschema.add_field(field_name=\"id\", datatype=DataType.INT64, is_primary=True)\nschema.add_field(field_name=\"vector\", datatype=DataType.FLOAT_VECTOR, dim=1024)\nschema.add_field(field_name=\"title\", datatype=DataType.VARCHAR, max_length=1024)\nschema.add_field(field_name=\"author\", datatype=DataType.VARCHAR, max_length=256)\nschema.add_field(field_name=\"paragraphs\", datatype=DataType.VARCHAR, max_length=10240)\nschema.add_field(field_name=\"type\", datatype=DataType.VARCHAR, max_length=128)\n```\n\n模式创建好了，接下来就可以创建集合了。\n```python\n# 创建集合\ntry:\n\tclient.create_collection(\n\t\tcollection_name=collection_name,\n\t\tschema=schema,\n\t\tshards_num=2\n\t)\n\tprint(f\"Created collection {collection_name}\")\nexcept Exception as e:\n\tprint(f\"Error occurred while creating collection: {e}\")\n```\n\n## 3 入库\n接下来把文件导入到 Milvus。\n```python\n# 读取和处理文件\nwith open(\"TangShi_vector.json\", 'r') as file:\n\tdata = json.load(file)\n\t# paragraphs的值是列表，需要从列表中取出字符串，取代列表，以符合Milvus插入数据的要求\n\tfor item in data:\n\t\titem[\"paragraphs\"] = item[\"paragraphs\"][0]\n\n# 将数据插入集合\nprint(f\"正在将数据插入集合：{collection_name}\")\nres = client.insert(\n\tcollection_name=collection_name,\n\tdata=data\n)\n```\n\n导入成功了吗？我们来验证下。\n```python\nprint(f\"插入的实体数量: {res['insert_count']}\")\n```\n\n返回插入实体的数量，看来是成功了。\n```shell\n插入的实体数量: 4307\n```\n\n## 4 创建索引\n向量已经导入 Milvus，现在可以搜索了吗？别急，为了提高搜索效率，我们还需要创建索引。什么是索引？一些大部头图书的最后，一般都会有索引，它列出了书中出现的关键术语以及对应的页码，帮助你快速找到它们的位置。如果没有索引，那就只能用笨方法，从第一页开始一页一页往后找了。\n\n![图片来源：自己拍的《英国皇家园艺学会植物繁育手册：用已有植物打造完美新植物》](https://picgo233.oss-cn-hangzhou.aliyuncs.com/img/202408232208878.jpeg)\n图片来源：自己拍的《英国皇家园艺学会植物繁育手册：用已有植物打造完美新植物》\n\nMilvus 的索引也是如此。如果不创建索引，虽然也可以搜索，但是速度很慢，它会逐一比较查询向量与数据库中每一个向量，通过指定方法计算出两个向量之间的 **距离**，找出距离最近的几个向量。而创建索引之后，搜索速度会大大提升。\n\n索引有不同的类型，适合不同的场景使用，我们以后会详细讨论这个问题。这里我们使用 IVF_FLAT。另外，计算**距离**的方法也有多种，我们使用 IP，也就是计算两个向量的内积。这些都是索引的参数，我们先创建这些参数。\n\n```python\n# 创建IndexParams对象，用于存储索引的各种参数\nindex_params = client.prepare_index_params()\n# 设置索引名称\nvector_index_name = \"vector_index\"\n# 设置索引的各种参数\nindex_params.add_index(\n\t# 指定为\"vector\"字段创建索引\n\tfield_name=\"vector\",\n\t# 设置索引类型\n\tindex_type=\"IVF_FLAT\",\n\t# 设置度量类型\n\tmetric_type=\"IP\",\n\t# 设置索引聚类中心的数量\n\tparams={\"nlist\": 128},\n\t# 指定索引名称\n\tindex_name=vector_index_name\n)\n```\n\n索引参数创建好了，现在终于可以创建索引了。\n```python\nprint(f\"开始创建索引：{vector_index_name}\")\n\n# 创建索引\nclient.create_index(\n\t# 指定为哪个集合创建索引\n\tcollection_name=collection_name,\n\t# 使用前面创建的索引参数创建索引\n\tindex_params=index_params\n)\n```\n\n我们来验证下索引是否创建成功了。\n```python\nindexes = client.list_indexes(\n\tcollection_name=collection_name\n)\nprint(f\"列出创建的索引：{indexes}\")\n```\n\n返回了包含索引名称的列表，索引名称 vector_index 正是我们之前创建的。\n```shell\n列出创建的索引：['vector_index']\n```\n  \n再来查看下索引的详情。\n```python\n# 查看索引详情\nindex_details = client.describe_index(\n\tcollection_name=collection_name,\n\t# 指定索引名称，这里假设使用第一个索引\n\tindex_name=\"vector_index\"\n)\nprint(f\"索引vector_index详情：{index_details}\")\n```\n\n返回了一个包含索引详细信息的字典，可以我们之前设置的索引参数，比如 nlist，index_type 和 metric_type 等等。\n```shell\n索引vector_index详情：{'nlist': '128', 'index_type': 'IVF_FLAT', 'metric_type': 'IP', 'field_name': 'vector', 'index_name': 'vector_index', 'total_rows': 0, 'indexed_rows': 0, 'pending_index_rows': 0, 'state': 'Finished'}\n```\n\n## 5 加载索引\n索引创建成功了，现在可以搜索了吗？等等，我们还需要把集合中的数据和索引，从硬盘加载到内存中。因为在内存中搜索更快。\n```python\nprint(f\"正在加载集合：{collection_name}\")\nclient.load_collection(collection_name=collection_name)\n```\n\n加载完成了，仍然验证下。\n```python\nprint(client.get_load_state(collection_name=collection_name))\n```\n\n返回加载状态 Loaded，没问题，加载完成。\n```shell\n{'state': <LoadState: Loaded>}\n```\n\n## 6 搜索\n经过前面的一系列准备，现在我们终于可以回到开头的问题了，用现代白话文搜索语义相似的古诗词。\n\n首先，把我们要搜索的现代白话文“翻译”成向量。\n```python\n# 获取查询向量\ntext = \"今天的雨好大\"\nquery_vectors = [vectorize_text([text])['dense'][0].tolist()]\n```\n\n然后，设置搜索参数，告诉 Milvus 怎么搜索。\n```python\n# 设置搜索参数\nsearch_params = {\n\t# 设置度量类型\n\t\"metric_type\": \"IP\",\n\t# 指定在搜索过程中要查询的聚类单元数量，增加nprobe值可以提高搜索精度，但会降低搜索速度\n\t\"params\": {\"nprobe\": 16}\n}\n```\n\n最后，我们还得告诉它怎么输出结果。\n```python\n# 指定搜索结果的数量，“limit=3”表示返回最相近的前3个搜索结果\nlimit = 3\n# 指定返回的字段\noutput_fields = [\"author\", \"title\", \"paragraphs\"]\n```\n\n一切就绪，让我们开始搜索吧！\n```python\nres1 = client.search(\n\tcollection_name=collection_name,\n\t# 指定查询向量\n\tdata=query_vectors,\n\t# 指定搜索的字段\n\tanns_field=\"vector\",\n\t# 设置搜索参数\n\tsearch_params=search_params,\n\t# 指定返回搜索结果的数量\n\tlimit=limit,\n\t# 指定返回的字段\n\toutput_fields=output_fields\n)\nprint(res1)\n```\n\n得到下面的结果：\n```shell\ndata: [\n    \"[\n        {\n            'id': 20002740,\n            'distance': 0.6542239189147949,\n            'entity': {\n                'title': '郊庙歌辞 享太庙乐章 大明舞',\n                'paragraphs': '旱望春雨，云披大风。',\n                'author': '张说'\n            }\n        },\n        {\n            'id': 20001658,\n            'distance': 0.6228379011154175,\n            'entity': {\n                'title': '三学山夜看圣灯',\n                'paragraphs': '细雨湿不暗，好风吹更明。',\n                'author': '蜀太妃徐氏'\n            }\n        },\n        {\n            'id': 20003360,\n            'distance': 0.6123768091201782,\n            'entity': {\n                'title': '郊庙歌辞 汉宗庙乐舞辞 积善舞',\n                'paragraphs': '云行雨施，天成地平。',\n                'author': '张昭'\n            }\n        }\n    ]\"\n]\n```\n\n在搜索结果中，id、title 等字段我们都了解了，只有 distance 是新出现的。它指的是搜索结果与查询向量之间的“距离”，具体含义和度量类型有关。我们使用的度量类型是 IP 内积，数字越大表示搜索结果和查询向量越接近。\n\n为了增加可读性，我们写一个输出函数：\n```python\n# 打印向量搜索结果\ndef print_vector_results(res):\n    # hit是搜索结果中的每一个匹配的实体\n    res = [hit[\"entity\"] for hit in res[0]]\n    for item in res:\n        print(f\"title: {item['title']}\")\n        print(f\"author: {item['author']}\")\n        print(f\"paragraphs: {item['paragraphs']}\")\n        print(\"-\"*50)   \n    print(f\"数量：{len(res)}\")\n```\n\n重新输出结果：\n```python\nprint_vector_results(res1)\n```\n\n这下搜索结果容易阅读了。\n```shell\ntitle: 郊庙歌辞 享太庙乐章 大明舞\nauthor: 张说\nparagraphs: 旱望春雨，云披大风。\n--------------------------------------------------\ntitle: 三学山夜看圣灯\nauthor: 蜀太妃徐氏\nparagraphs: 细雨湿不暗，好风吹更明。\n--------------------------------------------------\ntitle: 郊庙歌辞 汉宗庙乐舞辞 积善舞\nauthor: 张昭\nparagraphs: 云行雨施，天成地平。\n--------------------------------------------------\n数量：3\n```\n\n如果你不想限制搜索结果的数量，而是返回所有质量符合要求的搜索结果，可以修改搜索参数：\n```python\n# 修改搜索参数，设置距离的范围\nsearch_params = {\n\t\"metric_type\": \"IP\",\n\t\"params\": {\n\t\"nprobe\": 16,\n\t\"radius\": 0.55,\n\t\"range_filter\": 1.0\n\t}\n}\n```\n\n在搜索参数中增加 radius 和 range_filter 参数，它们限制了距离 distance 的范围在0.55到1之间。然后调整搜索代码，删除 limit 参数。\n```python\nres2 = client.search(\n\tcollection_name=collection_name,\n\t# 指定查询向量\n\tdata=query_vectors,\n\t# 指定搜索的字段\n\tanns_field=\"vector\",\n\t# 设置搜索参数\n\tsearch_params=search_params,\n\t# 删除limit参数\n\t# 指定返回的字段\n\toutput_fields=output_fields\n)\nprint(res2)\n```\n\n可以看到，输出结果的 distance 都大于0.55。\n```python\ndata: [\n    \"[\n        {\n            'id': 20002740,\n            'distance': 0.6542239189147949,\n            'entity': {\n                'author': '张说',\n                'title': '郊庙歌辞 享太庙乐章 大明舞',\n                'paragraphs': '旱望春雨，云披大风。'\n            }\n        },\n        {\n            'id': 20001658,\n            'distance': 0.6228379011154175,\n            'entity': {\n                'author': '蜀太妃徐氏',\n                'title': '三学山夜看圣灯',\n                'paragraphs': '细雨湿不暗，好风吹更明。'\n            }\n        },\n        {\n            'id': 20003360,\n            'distance': 0.6123768091201782,\n            'entity': {\n                'author': '张昭',\n                'title': '郊庙歌辞 汉宗庙乐舞辞 积善舞',\n                'paragraphs': '云行雨施，天成地平。'\n            }\n        },\n        {\n            'id': 20003608,\n            'distance': 0.5755923986434937,\n            'entity': {\n                'author': '李端',\n                'title': '鼓吹曲辞 巫山高',\n                'paragraphs': '回合云藏日，霏微雨带风。'\n            }\n        },\n        {\n            'id': 20000992,\n            'distance': 0.5700664520263672,\n            'entity': {\n                'author': '德宗皇帝',\n                'title': '九月十八赐百僚追赏因书所怀',\n                'paragraphs': '雨霁霜气肃，天高云日明。'\n            }\n        },\n        {\n            'id': 20002246,\n            'distance': 0.5583387613296509,\n            'entity': {\n                'author': '不详',\n                'title': '郊庙歌辞 祭方丘乐章 顺和',\n                'paragraphs': '雨零感节，云飞应序。'\n            }\n        }\n    ]\"\n]\n```\n\n也许你还想知道你最喜欢的李白，有没有和你一样感慨今天的雨真大，没问题，我们增加filter参数就可以了。\n```python\n# 通过表达式过滤字段author，筛选出字段“author”的值为“李白”的结果\nfilter = f\"author == '李白'\"\n\nres3 = client.search(\n\tcollection_name=collection_name,\n\t# 指定查询向量\n\tdata=query_vectors,\n\t# 指定搜索的字段\n\tanns_field=\"vector\",\n\t# 设置搜索参数\n\tsearch_params=search_params,\n\t# 通过表达式实现标量过滤，筛选结果\n\tfilter=filter,\n\t# 指定返回搜索结果的数量\n\tlimit=limit,\n\t# 指定返回的字段\n\toutput_fields=output_fields\n)\nprint(res3)\n```\n\n返回的结果为空值。\n```python\ndata: ['[]'] \n```\n\n这是因为我们前面设置了 distance 的范围在0.55到1之间，放大范围可以获得更多结果。把 \"radius\" 的值修改为0.2，再次运行命令，让我们看看李白是怎么感慨的。\n```python\ndata: [\n    \"[\n        {\n            'id': 20004246,\n            'distance': 0.46472394466400146,\n            'entity': {\n                'author': '李白',\n                'title': '横吹曲辞 关山月',\n                'paragraphs': '明月出天山，苍茫云海间。'\n            }\n        },\n        {\n            'id': 20003707,\n            'distance': 0.4347272515296936,\n            'entity': {\n                'author': '李白',\n                'title': '鼓吹曲辞 有所思',\n                'paragraphs': '海寒多天风，白波连山倒蓬壶。'\n            }\n        },\n        {\n            'id': 20003556,\n            'distance': 0.40778297185897827,\n            'entity': {\n                'author': '李白',\n                'title': '鼓吹曲辞 战城南',\n                'paragraphs': '去年战桑干源，今年战葱河道。'\n            }\n        }\n    ]\"\n]\n```\n\n我们观察搜索结果发现， distance 在0.4左右，小于之前设置的0.55，所以被排除了。另外，distance 数值较小，说明搜索结果并不是特别接近查询向量，而这几句诗词的确和“雨”的关系比较远。\n\n如果你希望搜索结果中直接包含“雨”字，可以使用 query 方法做标量搜索。\n```python\n# paragraphs字段包含“雨”字\nfilter = f\"paragraphs like '%雨%'\"\n\nres4 = client.query(\n\tcollection_name=collection_name,\n\tfilter=filter,\n\toutput_fields=output_fields,\n\tlimit=limit\n)\nprint(res4)\n```\n\n标量查询的代码更简单，因为它免去了和向量搜索相关的参数，比如查询向量 data，指定搜索字段的 anns_field 和搜索参数 search_params，搜索参数只有 filter 。\n\n观察搜索结果发现，标量搜索结果的数据结构少了一个 “[]”，我们在提取具体字段时需要注意这一点。\n```python\ndata: [\n    \"{\n        \"author\": \"太宗皇帝\",\n        \"title\": \"咏雨\",\n        \"paragraphs\": \"罩云飘远岫，喷雨泛长河。\",\n        \"id\": 20000305\n    },\n    {\n        \"author\": \"太宗皇帝\",\n        \"title\": \"咏雨\",\n        \"paragraphs\": \"和气吹绿野，梅雨洒芳田。\",\n        \"id\": 20000402\n    },\n    {\n        \"author\": \"太宗皇帝\",\n        \"title\": \"赋得花庭雾\",\n        \"paragraphs\": \"还当杂行雨，髣髴隐遥空。\",\n        \"id\": 20000421\n    }\"\n]\n```\n\nfilter 表达式还有丰富的用法，比如同时搜索两个字段，author 字段指定为 “杜甫”，同时 paragraphs 字段仍然要求包含“雨”字：\n```python\nfilter = f\"author == '杜甫' && paragraphs like '%雨%'\"\n\nres5 = client.query(\n\tcollection_name=collection_name,\n\tfilter=filter,\n\toutput_fields=output_fields,\n\tlimit=limit\n)\nprint(res5)\n```\n\n返回杜甫含有“雨”字的诗句：\n```python\ndata: [\n\t\"{\n\t\t'title': '横吹曲辞 前出塞九首 七', \n\t\t'paragraphs': '驱马天雨雪，军行入高山。', \n\t\t'id': 20004039, \n\t\t'author': '杜甫'\n\t}\"\n] \n```\n\n更多标量搜索的表达式可以参考[Get & Scalar Query](https://milvus.io/docs/get-and-scalar-query.md#Use-Basic-Operators)。\n\n## 总结\n可能这样的搜索结果并没有让你很满意，这里面有多个原因。首先，数据集太小了。只有4000多个句子，语义更接近的句子可能没有包含其中。其次，嵌入模型虽然支持中文，但是古诗词并不是它的专长。这就好像你找了个翻译帮你和老外交流，翻译虽然懂普通话，但是你满嘴四川方言，翻译也只能也蒙带猜，翻译质量可想而知。\n\n如果你希望优化搜索功能，可以在 [chinese-poetry](https://github.com/BushJiang/chinese-poetry) 下载完整的古诗词数据集，再找找专门用于古诗词的嵌入模型，相信搜索效果会有较大提升。\n\n另外，我在以上代码的基础上，开发了一个命令行应用，有兴趣可以玩玩：[语义搜索古诗词](https://github.com/BushJiang/searchPoems)\n\n## 参考\n[^1]:古诗词数据集来自 [chinese-poetry](https://github.com/BushJiang/chinese-poetry)，数据结构做了调整。","categories":["向量数据库","原理探秘"]}]